{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da98d174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvzone in c:\\users\\kwang\\anaconda3\\lib\\site-packages (1.5.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\kwang\\anaconda3\\lib\\site-packages (from cvzone) (4.5.5.64)\n",
      "Requirement already satisfied: numpy in c:\\users\\kwang\\anaconda3\\lib\\site-packages (from cvzone) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384ffd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cvzone.HandTrackingModule import HandDetector\n",
    "import cv2, cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752793d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Find the hand and its landmarks\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     img \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mfindHands(img)\n\u001b[1;32m---> 13\u001b[0m     lmList, bbox \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mfindHands(img)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#     findPosition(img)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Display\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "detector = handDetector()\n",
    "# HandDetector(detectionCon=0.5, maxHands=1)\n",
    "\n",
    "while True:\n",
    "    # Get image frame\n",
    "    success, img = cap.read()\n",
    "\n",
    "    # Find the hand and its landmarks\n",
    "    img = detector.findHands(img)\n",
    "    lmList, bbox = detector.findHands(img)\n",
    "#     findPosition(img)\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87844ab3",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Find the hand and its landmarks\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m hands, img \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindHands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# with draw\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# hands = detector.findHands(img, draw=False)  # without draw\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hands:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Hand 1\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\cvzone\\HandTrackingModule.py:48\u001b[0m, in \u001b[0;36mHandDetector.findHands\u001b[1;34m(self, img, draw, flipType)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindHands\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, flipType\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    Finds hands in a BGR image.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    :param img: Image to find the hands in.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    :param draw: Flag to draw the output on the image.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    :return: Image with or without drawings\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     imgRGB \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhands\u001b[38;5;241m.\u001b[39mprocess(imgRGB)\n\u001b[0;32m     50\u001b[0m     allHands \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8, maxHands=2)\n",
    "while True:\n",
    "    # Get image frame\n",
    "    success, img = cap.read()\n",
    "    # Find the hand and its landmarks\n",
    "    hands, img = detector.findHands(img)  # with draw\n",
    "    # hands = detector.findHands(img, draw=False)  # without draw\n",
    "\n",
    "    if hands:\n",
    "        # Hand 1\n",
    "        hand1 = hands[0]\n",
    "        lmList1 = hand1[\"lmList\"]  # List of 21 Landmark points\n",
    "        bbox1 = hand1[\"bbox\"]  # Bounding box info x,y,w,h\n",
    "        centerPoint1 = hand1['center']  # center of the hand cx,cy\n",
    "        handType1 = hand1[\"type\"]  # Handtype Left or Right\n",
    "\n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "\n",
    "        if len(hands) == 2:\n",
    "            # Hand 2\n",
    "            hand2 = hands[1]\n",
    "            lmList2 = hand2[\"lmList\"]  # List of 21 Landmark points\n",
    "            bbox2 = hand2[\"bbox\"]  # Bounding box info x,y,w,h\n",
    "            centerPoint2 = hand2['center']  # center of the hand cx,cy\n",
    "            handType2 = hand2[\"type\"]  # Hand Type \"Left\" or \"Right\"\n",
    "\n",
    "            fingers2 = detector.fingersUp(hand2)\n",
    "\n",
    "            # Find Distance between two Landmarks. Could be same hand or different hands\n",
    "            length, info, img = detector.findDistance(lmList1[8], lmList2[8], img)  # with draw\n",
    "            # length, info = detector.findDistance(lmList1[8], lmList2[8])  # with draw\n",
    "    # Display\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2aca1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Find the hand and its landmarks\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindHands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m lmList, bbox \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mfindPosition(img, draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Draw  Corner Rectangle\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\cvzone\\HandTrackingModule.py:48\u001b[0m, in \u001b[0;36mHandDetector.findHands\u001b[1;34m(self, img, draw, flipType)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindHands\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, flipType\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    Finds hands in a BGR image.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    :param img: Image to find the hands in.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    :param draw: Flag to draw the output on the image.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    :return: Image with or without drawings\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     imgRGB \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhands\u001b[38;5;241m.\u001b[39mprocess(imgRGB)\n\u001b[0;32m     50\u001b[0m     allHands \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cvzone\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector()\n",
    "\n",
    "while True:\n",
    "    # Get image frame\n",
    "    success, img = cap.read()\n",
    "\n",
    "    # Find the hand and its landmarks\n",
    "    img = detector.findHands(img, draw=False)\n",
    "    lmList, bbox = detector.findPosition(img, draw=False)\n",
    "    if bbox:\n",
    "        # Draw  Corner Rectangle\n",
    "        cvzone.cornerRect(img, bbox)\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede857fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 450, 267]\n",
      "[4, 451, 268]\n",
      "[4, 437, 266]\n",
      "[4, 441, 260]\n",
      "[4, 444, 260]\n",
      "[4, 450, 252]\n",
      "[4, 449, 261]\n",
      "[4, 453, 257]\n",
      "[4, 452, 257]\n",
      "[4, 442, 261]\n",
      "[4, 447, 260]\n",
      "[4, 446, 259]\n",
      "[4, 301, 267]\n",
      "[4, 303, 270]\n",
      "[4, 325, 252]\n",
      "[4, 331, 248]\n",
      "[4, 342, 248]\n",
      "[4, 346, 245]\n",
      "[4, 346, 244]\n",
      "[4, 347, 245]\n",
      "[4, 341, 247]\n",
      "[4, 342, 248]\n",
      "[4, 342, 248]\n",
      "[4, 338, 251]\n",
      "[4, 335, 251]\n",
      "[4, 332, 252]\n",
      "[4, 333, 254]\n",
      "[4, 332, 254]\n",
      "[4, 332, 254]\n",
      "[4, 331, 256]\n",
      "[4, 328, 255]\n",
      "[4, 328, 256]\n",
      "[4, 326, 255]\n",
      "[4, 326, 255]\n",
      "[4, 326, 255]\n",
      "[4, 326, 254]\n",
      "[4, 326, 255]\n",
      "[4, 326, 255]\n",
      "[4, 326, 255]\n",
      "[4, 326, 260]\n",
      "[4, 325, 261]\n",
      "[4, 326, 261]\n",
      "[4, 263, 243]\n",
      "[4, 241, 239]\n",
      "[4, 252, 240]\n",
      "[4, 254, 241]\n",
      "[4, 222, 190]\n",
      "[4, 201, 179]\n",
      "[4, 210, 180]\n",
      "[4, 223, 189]\n",
      "[4, 218, 187]\n",
      "[4, 243, 194]\n",
      "[4, 244, 217]\n",
      "[4, 247, 234]\n",
      "[4, 238, 252]\n",
      "[4, 244, 253]\n",
      "[4, 241, 252]\n",
      "[4, 239, 247]\n",
      "[4, 240, 254]\n",
      "[4, 243, 248]\n",
      "[4, 245, 250]\n",
      "[4, 194, 253]\n",
      "[4, 194, 261]\n",
      "[4, 194, 255]\n",
      "[4, 431, 267]\n",
      "[4, 427, 267]\n",
      "[4, 419, 258]\n",
      "[4, 418, 262]\n",
      "[4, 416, 245]\n",
      "[4, 416, 247]\n",
      "[4, 417, 247]\n",
      "[4, 417, 251]\n",
      "[4, 424, 256]\n",
      "[4, 426, 253]\n",
      "[4, 434, 246]\n",
      "[4, 434, 246]\n",
      "[4, 434, 250]\n",
      "[4, 433, 251]\n",
      "[4, 434, 250]\n",
      "[4, 423, 257]\n",
      "[4, 423, 257]\n",
      "[4, 412, 255]\n",
      "[4, 412, 255]\n",
      "[4, 411, 255]\n",
      "[4, 407, 255]\n",
      "[4, 412, 258]\n",
      "[4, 414, 258]\n",
      "[4, 415, 257]\n",
      "[4, 444, 237]\n",
      "[4, 444, 238]\n",
      "[4, 457, 241]\n",
      "[4, 459, 241]\n",
      "[4, 459, 242]\n",
      "[4, 462, 248]\n",
      "[4, 464, 248]\n",
      "[4, 463, 248]\n",
      "[4, 463, 247]\n",
      "[4, 464, 249]\n",
      "[4, 462, 245]\n",
      "[4, 460, 243]\n",
      "[4, 404, 225]\n",
      "[4, 403, 247]\n",
      "[4, 357, 232]\n",
      "[4, 359, 231]\n",
      "[4, 349, 236]\n",
      "[4, 350, 236]\n",
      "[4, 344, 234]\n",
      "[4, 342, 234]\n",
      "[4, 365, 138]\n",
      "[4, 384, 143]\n",
      "[4, 365, 152]\n",
      "[4, 344, 236]\n",
      "[4, 346, 231]\n",
      "[4, 343, 235]\n",
      "[4, 344, 231]\n",
      "[4, 367, 137]\n",
      "[4, 379, 140]\n",
      "[4, 375, 143]\n",
      "[4, 377, 144]\n",
      "[4, 371, 157]\n",
      "[4, 371, 165]\n",
      "[4, 369, 165]\n",
      "[4, 383, 177]\n",
      "[4, 368, 163]\n",
      "[4, 361, 158]\n",
      "[4, 366, 152]\n",
      "[4, 380, 134]\n",
      "[4, 375, 133]\n",
      "[4, 350, 228]\n",
      "[4, 345, 232]\n",
      "[4, 344, 231]\n",
      "[4, 350, 229]\n",
      "[4, 354, 225]\n",
      "[4, 360, 224]\n",
      "[4, 398, 139]\n",
      "[4, 403, 142]\n",
      "[4, 403, 151]\n",
      "[4, 405, 151]\n",
      "[4, 404, 150]\n",
      "[4, 404, 151]\n",
      "[4, 404, 156]\n",
      "[4, 376, 235]\n",
      "[4, 374, 231]\n",
      "[4, 346, 232]\n",
      "[4, 345, 234]\n",
      "[4, 296, 263]\n",
      "[4, 306, 264]\n",
      "[4, 303, 258]\n",
      "[4, 363, 227]\n",
      "[4, 366, 230]\n",
      "[4, 411, 152]\n",
      "[4, 411, 151]\n",
      "[4, 412, 159]\n",
      "[4, 326, 233]\n",
      "[4, 377, 259]\n",
      "[4, 384, 248]\n",
      "[4, 383, 244]\n",
      "[4, 417, 249]\n",
      "[4, 427, 233]\n",
      "[4, 427, 229]\n",
      "[4, 427, 228]\n",
      "[4, 445, 220]\n",
      "[4, 452, 219]\n",
      "[4, 449, 218]\n",
      "[4, 451, 219]\n",
      "[4, 451, 217]\n",
      "[4, 452, 217]\n",
      "[4, 451, 217]\n",
      "[4, 453, 218]\n",
      "[4, 455, 216]\n",
      "[4, 454, 218]\n",
      "[4, 464, 216]\n",
      "[4, 348, 212]\n",
      "[4, 378, 258]\n",
      "[4, 366, 250]\n",
      "[4, 383, 221]\n",
      "[4, 384, 222]\n",
      "[4, 374, 222]\n",
      "[4, 377, 223]\n",
      "[4, 373, 222]\n",
      "[4, 370, 223]\n",
      "[4, 370, 224]\n",
      "[4, 372, 230]\n",
      "[4, 369, 224]\n",
      "[4, 368, 228]\n",
      "[4, 374, 214]\n",
      "[4, 374, 203]\n",
      "[4, 551, 210]\n",
      "[4, 452, 255]\n",
      "[4, 412, 289]\n",
      "[4, 411, 291]\n",
      "[4, 410, 280]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# class creation\n",
    "class handDetector():\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5,modelComplexity=1,trackCon=0.5):\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.modelComplex = modelComplexity\n",
    "        self.trackCon = trackCon\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands,self.modelComplex,\n",
    "                                        self.detectionCon, self.trackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils # it gives small dots onhands total 20 landmark points\n",
    "\n",
    "    def findHands(self,img,draw=True):\n",
    "        # Send rgb image to hands\n",
    "        imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB) # process the frame\n",
    "    #     print(results.multi_hand_landmarks)\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "\n",
    "                if draw:\n",
    "                    #Draw dots and connect them\n",
    "                    self.mpDraw.draw_landmarks(img,handLms,\n",
    "                                                self.mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def findPosition(self,img, handNo=0, draw=True):\n",
    "        \"\"\"Lists the position/type of landmarks\n",
    "        we give in the list and in the list ww have stored\n",
    "        type and position of the landmarks.\n",
    "        List has all the lm position\"\"\"\n",
    "\n",
    "        lmlist = []\n",
    "\n",
    "        # check wether any landmark was detected\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            #Which hand are we talking about\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            # Get id number and landmark information\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                # id will give id of landmark in exact index number\n",
    "                # height width and channel\n",
    "                h,w,c = img.shape\n",
    "                #find the position\n",
    "                cx,cy = int(lm.x*w), int(lm.y*h) #center\n",
    "                # print(id,cx,cy)\n",
    "                lmlist.append([id,cx,cy])\n",
    "\n",
    "                # Draw circle for 0th landmark\n",
    "                if draw:\n",
    "                    cv2.circle(img,(cx,cy), 15 , (255,0,255), cv2.FILLED)\n",
    "\n",
    "        return lmlist\n",
    "\n",
    "def main():\n",
    "    #Frame rates\n",
    "    pTime = 0\n",
    "    cTime = 0\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector = handDetector()\n",
    "\n",
    "    while True:\n",
    "        success,img = cap.read()\n",
    "        img = detector.findHands(img)\n",
    "        lmList = detector.findPosition(img)\n",
    "        if len(lmList) != 0:\n",
    "            print(lmList[4])\n",
    "\n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime-pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        cv2.putText(img,str(int(fps)),(10,70), cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    "\n",
    "        cv2.imshow(\"Video\",img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8eead26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b6afe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12dc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
